@article{article,
  author = {Sultana, Sadia and Rahman, Mohammad},
  year = {2023},
  month = {05},
  pages = {157-166},
  title = {Acoustic feature analysis and optimization for Bangla speech emotion recognition},
  volume = {44},
  journal = {Acoustical Science and Technology},
  doi = {10.1250/ast.44.157}
}
@book{goldstein2001blackwell,
  title={Blackwell Handbook of Perception},
  author={Goldstein, E.B. and Humphreys, G. and Shiffrar, M. and Yost, W.},
  isbn={9780631206835},
  lccn={00063050},
  series={Blackwell Handbooks of Experimental Psychology},
  url={https://books.google.com.bd/books?id=I5k0jC0MbXcC},
  year={2001},
  publisher={Wiley}
}
@article{DAS2022108091,
  title = {BanglaSER: A speech emotion recognition dataset for the Bangla language},
  journal = {Data in Brief},
  volume = {42},
  pages = {108091},
  year = {2022},
  issn = {2352-3409},
  doi = {https://doi.org/10.1016/j.dib.2022.108091},
  url = {https://www.sciencedirect.com/science/article/pii/S235234092200302X},
  author = {Rakesh Kumar Das and Nahidul Islam and Md. Rayhan Ahmed and Salekul Islam and Swakkhar Shatabda and A.K.M. Muzahidul Islam},
  keywords = {Speech emotion recognition, Sound processing, Deep Learning, Bangla language},
  abstract = {The speech emotion recognition system determines a speaker's emotional state by analyzing his/her speech audio signal. It is an essential at the same time a challenging task in human-computer interaction systems and is one of the most demanding areas of research using artificial intelligence and deep machine learning architectures. Despite being the world's seventh most widely spoken language, Bangla is still classified as one of the low-resource languages for speech emotion recognition tasks because of inadequate availability of data. There is an apparent lack of speech emotion recognition dataset to perform this type of research in Bangla language. This article presents a Bangla language-based emotional speech-audio recognition dataset to address this problem. BanglaSER is a Bangla language-based speech emotion recognition dataset. It consists of speech-audio data of 34 participating speakers from diverse age groups between 19 and 47 years, with a balanced 17 male and 17 female nonprofessional participating actors. This dataset contains 1467 Bangla speech-audio recordings of five rudimentary human emotional states, namely angry, happy, neutral, sad, and surprise. Three trials are conducted for each emotional state. Hence, the total number of recordings involves 3 statements × 3 repetitions × 4 emotional states (angry, happy, sad, and surprise) × 34 participating speakers = 1224 recordings + 3 statements × 3 repetitions × 1 emotional state (neutral) × 27 participating speakers = 243 recordings, resulting in a total number of recordings of 1467. BanglaSER dataset is created by recording speech-audios through smartphones, and laptops, having a balanced number of recordings in each category with evenly distributed participating male and female actors, and would serve as an essential training dataset for the Bangla speech emotion recognition model in terms of generalization. BanglaSER is compatible with various deep learning architectures such as Convolutional neural networks, Long short-term memory, Gated recurrent unit, Transformer, etc. The dataset is available at https://data.mendeley.com/datasets/t9h6p943xy/5 and can be used for research purposes.}
}
@article{article2,
  author = {Sultana, Sadia and Iqbal, Muhammed and Selim, Mohammad and Rashid, MD and Rahman, M.},
  year = {2022},
  month = {01},
  pages = {564-578},
  title = {Bangla Speech Emotion Recognition and Cross-lingual Study Using Deep CNN and BLSTM Networks},
  volume = {10},
  journal = {IEEE Access},
  doi = {10.1109/ACCESS.2021.3136251}
}
@article{sultana2021sust,
  title={SUST Bangla Emotional Speech Corpus (SUBESCO): An audio-only emotional speech corpus for Bangla},
  author={Sultana, Sadia and Rahman, M Shahidur and Selim, M Reza and Iqbal, M Zafar},
  journal={Plos one},
  volume={16},
  number={4},
  pages={e0250173},
  year={2021},
  publisher={Public Library of Science San Francisco, CA USA}
}
@article{billah2023kbes,
  title={KBES: A dataset for realistic Bangla speech emotion recognition with intensity level},
  author={Billah, Md Masum and Sarker, Md Likhon and Akhand, MAH},
  journal={Data in Brief},
  volume={51},
  pages={109741},
  year={2023},
  publisher={Elsevier}
}
@article{jahangir2021deep,
  title={Deep learning approaches for speech emotion recognition: State of the art and research challenges},
  author={Jahangir, Rashid and Teh, Ying Wah and Hanif, Faiqa and Mujtaba, Ghulam},
  journal={Multimedia Tools and Applications},
  volume={80},
  number={16},
  pages={23745--23812},
  year={2021},
  publisher={Springer}
}
@book{aizawa2004advances,
  title={Advances in Multimedia Information Processing-PCM 2004: 5th Pacific Rim Conference on Multimedia, Tokyo, Japan, November 30-December 3, 2004, Proceedings},
  author={Aizawa, Kiyoharu and Nakamura, Yuichi and Satoh, Shin'ichi},
  volume={3332},
  year={2004},
  publisher={Springer Science \& Business Media}
}
@inproceedings{abdulsatar2019age,
  title={Age and gender recognition from speech signals},
  author={Abdulsatar, Assim Ara and Davydov, VV and Yushkova, VV and Glinushkin, AP and Rud, V Yu},
  booktitle={Journal of Physics: Conference Series},
  volume={1410},
  pages={012073},
  year={2019},
  organization={IOP Publishing}
}
@article{2009DSP....19..153S,
       author = {{Sejdi{\'c}}, Ervin and {Djurovi{\'c}}, Igor and {Jiang}, Jin},
        title = "{Time-frequency feature representation using energy concentration: An overview of recent advances}",
      journal = {Digital Signal Processing},
     keywords = {Time-frequency analysis, Energy concentration, Feature extraction and classification},
         year = 2009,
        month = jan,
       volume = {19},
       number = {1},
        pages = {153-183},
          doi = {10.1016/j.dsp.2007.12.004},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2009DSP....19..153S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@ARTICLE{1964ASAJ...36.2346S,
       author = {{Shepard}, Roger N.},
        title = "{Circularity in Judgments of Relative Pitch}",
      journal = {Acoustical Society of America Journal},
         year = 1964,
        month = jan,
       volume = {36},
       number = {12},
        pages = {2346},
          doi = {10.1121/1.1919362},
       adsurl = {https://ui.adsabs.harvard.edu/abs/1964ASAJ...36.2346S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@ARTICLE{1978ASAJ...63.1493G,
       author = {{Grey}, John M. and {Gordon}, John W.},
        title = "{Perceptual effects of spectral modifications on musical timbres}",
      journal = {Acoustical Society of America Journal},
         year = 1978,
        month = may,
       volume = {63},
       number = {5},
        pages = {1493-1500},
          doi = {10.1121/1.381843},
       adsurl = {https://ui.adsabs.harvard.edu/abs/1978ASAJ...63.1493G},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@ARTICLE{1688199,
  author={Polikar, R.},
  journal={IEEE Circuits and Systems Magazine}, 
  title={Ensemble based systems in decision making}, 
  year={2006},
  volume={6},
  number={3},
  pages={21-45},
  keywords={Decision making;Computational intelligence;Bagging;Boosting;Voting;Estimation error;Error correction codes;Game theory;TV;Telephony},
  doi={10.1109/MCAS.2006.1688199}
}
@inproceedings{inproceedings,
author = {Raouzaiou, Amaryllis and Karpouzis, Kostas and Kollias, Stefanos},
year = {2004},
month = {01},
pages = {44-52},
title = {Emotion Synthesis in Virtual Environments},
isbn = {1-4020-3674-4},
doi = {10.1007/1-4020-3675-2_36}
}
@article{Cortes1995,
  author = {Cortes, Corinna and Vapnik, Vladimir},
  title = {Support-vector networks},
  journal = {Machine Learning},
  year = {1995},
  volume = {20},
  number = {3},
  pages = {273--297},
  month = {Sep},
  abstract = {The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensure high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
  issn = {1573-0565},
  url = {https://doi.org/10.1007/BF00994018},
  doi = {10.1007/BF00994018}
}
